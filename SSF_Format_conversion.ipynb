{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da161b24-fb1e-4a60-86a2-d237e5e45ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the absolute path of the input file:  /home/alexander/Desktop/LTRC_IIIT_HYD/XML_frmt/temp_sample_ssf.txt\n",
      "Enter the absolute path of the output directory:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to: /home/alexander/Downloads\n",
      "File saved to: /home/alexander/Downloads/output.txt\n",
      "Output written to: /home/alexander/Downloads/SSF_Conv_output_2024-08-21_19-23-10.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "#from collections import defaultdict\n",
    "\n",
    "# Store words by sentence id\n",
    "sentence_words = {}\n",
    "\n",
    "# To maintain unique identifiers for anaphoras\n",
    "anaphora_counter = 0\n",
    "anaphora_map = {}  # Dictionary to map anaphoras to their identifiers\n",
    "antecedent_map = {}  # Dictionary to map antecedents to their anaphoras' identifiers\n",
    "antecedent_colors = {}  # Dictionary to store colors for antecedents\n",
    "anaphora_colors = {}  # Dictionary to map anaphoras to their identifiers\n",
    "color_word_map = {}  # Dictionary to map color codes to their corresponding words\n",
    "tagged_word_id = 1  # Unique ID counter for all tagged words\n",
    "\n",
    "def extract_elements(sentence):\n",
    "    elements = {}\n",
    "    lines = sentence.split('\\n')\n",
    "\n",
    "    current_element = {}\n",
    "    current_chunk = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if re.match(r'^\\d+\\s+\\(\\(', line):  # Start of a new element\n",
    "            if current_chunk:\n",
    "                elements[' '.join(current_chunk)] = current_element\n",
    "            current_element = {}\n",
    "            current_chunk = []\n",
    "            element_id_match = re.search(r'^\\d+', line)\n",
    "            if element_id_match:\n",
    "                current_element['element_id'] = element_id_match.group(0)\n",
    "            name_match = re.search(r'name=(NP\\d+)', line)\n",
    "            if name_match:\n",
    "                current_element['name'] = name_match.group(1)\n",
    "            current_element['ref_sentence_id'] = None\n",
    "            current_element['ref_name'] = None\n",
    "\n",
    "        elif re.match(r'^\\d+\\.\\d+\\s+\\S+', line):  # This line contains the actual word details or punctuation.\n",
    "            word_match = re.match(r'^\\d+\\.\\d+\\s+(\\S+)', line)\n",
    "            if word_match:\n",
    "                word = word_match.group(1)\n",
    "                current_chunk.append(word)\n",
    "\n",
    "            # Extract ref_sentence_id and REF if present\n",
    "            ref_sentence_id_match = re.search(r'sentence\\s?id\\s?=\\s?[\\'\"]?(\\d+)[\\'\"]?', line)\n",
    "            if ref_sentence_id_match:\n",
    "                current_element['ref_sentence_id'] = ref_sentence_id_match.group(1)\n",
    "            ref_name_match = re.search(r'REF=(NP\\d+)', line)\n",
    "            if ref_name_match:\n",
    "                current_element['ref_name'] = ref_name_match.group(1)\n",
    "\n",
    "        elif line == '))':  # End of a chunk\n",
    "            current_element['combined_chunk'] = ' '.join(current_chunk)\n",
    "            elements[' '.join(current_chunk)] = current_element\n",
    "            current_element = {}\n",
    "            current_chunk = []\n",
    "\n",
    "    #print(elements)\n",
    "    return elements\n",
    "\n",
    "\n",
    "def generate_random_hex_color():\n",
    "    letters = '89ABCDEF'\n",
    "    hex_color = ''.join(random.choice(letters) for _ in range(6))\n",
    "    return f\"#{hex_color}\"\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    rgb = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return f\"rgb({rgb[0]}, {rgb[1]}, {rgb[2]})\"\n",
    "\n",
    "def rgb_to_hex(rgb_string):\n",
    "    rgb_values = rgb_string.strip('rgb()').split(',')  # Extract RGB values from string\n",
    "    if len(rgb_values) == 3:\n",
    "        r, g, b = [int(value.strip()) for value in rgb_values]\n",
    "        return '#{:02X}{:02X}{:02X}'.format(r, g, b)\n",
    "    else:\n",
    "        return 'N/A'  # Handle cases where the RGB string is invalid\n",
    "\n",
    "def generate_random_color():\n",
    "    hex_color = generate_random_hex_color()\n",
    "    return hex_to_rgb(hex_color)\n",
    "\n",
    "count = 0\n",
    "\n",
    "def tag_coreferences(all_elements):\n",
    "    global sentence_words, anaphora_counter, tagged_word_id\n",
    "\n",
    "    # New dictionary to store antecedent IDs and their corresponding words\n",
    "    antecedent_id_map = {}\n",
    "\n",
    "    # Iterate over each sentence in the input elements\n",
    "    for i, elements in enumerate(all_elements):\n",
    "        words = []\n",
    "\n",
    "        # Process each word in the current sentence\n",
    "        for word, word_info in elements.items():\n",
    "            if word_info.get('ref_sentence_id'):\n",
    "                # Increment the anaphora counter for each anaphora found\n",
    "                anaphora_counter += 1\n",
    "                \n",
    "                # Create a superscript tag for the current anaphora\n",
    "                anaphora_id = f\"<sup> {anaphora_counter} </sup>\"\n",
    "                anaphora_map[anaphora_id] = word\n",
    "\n",
    "                # Extract the referenced sentence index and name\n",
    "                ref_sentence_index = int(word_info['ref_sentence_id']) - 1\n",
    "                ref_name = word_info['ref_name']\n",
    "                ref_sentence_id_key = f\"Sentence {ref_sentence_index + 1}\"\n",
    "\n",
    "                # Retrieve the elements from the referenced sentence\n",
    "                ref_elements = all_elements[ref_sentence_index]\n",
    "                referenced_element_info = None\n",
    "                \n",
    "                # Find the referenced element's information\n",
    "                for element_name, element_info in ref_elements.items():\n",
    "                    if element_info['name'] == ref_name:\n",
    "                        referenced_element_info = element_info\n",
    "                        break\n",
    "\n",
    "                # Get the combined chunk of the anaphora\n",
    "                combined_chunk = word_info.get('combined_chunk', '')\n",
    "                antecedent_word = referenced_element_info['combined_chunk'] if referenced_element_info else None\n",
    "\n",
    "                # Determine the color for the anaphora\n",
    "                if antecedent_word and antecedent_word in antecedent_colors:\n",
    "                    color = antecedent_colors[antecedent_word]\n",
    "                elif antecedent_word and antecedent_word in anaphora_colors:\n",
    "                    color = anaphora_colors[antecedent_word]\n",
    "                elif combined_chunk in anaphora_colors:\n",
    "                    color = anaphora_colors[combined_chunk]\n",
    "                elif combined_chunk in antecedent_colors:\n",
    "                    color = antecedent_colors[combined_chunk]\n",
    "                else:\n",
    "                    # Generate a new random color if none is assigned\n",
    "                    color = generate_random_color()\n",
    "                    if antecedent_word:\n",
    "                        antecedent_colors[antecedent_word] = color\n",
    "                    anaphora_colors[combined_chunk] = color\n",
    "\n",
    "                # Add to the color_word_map for tracking colors\n",
    "                word_tag_id = f\"{tagged_word_id}\"\n",
    "                id_anaphora = word_tag_id\n",
    "                color_word_map[word_tag_id] = {'word': combined_chunk, 'color': color}\n",
    "                tagged_word_id += 1\n",
    "\n",
    "                # Append the anaphora HTML with its ID and style\n",
    "                #words.append(f\"<anaphora id=\\\"{id_anaphora}\\\" class=\\\"highlightAnnaphora\\\" ana_ref=\\\"TRUE\\\" ana_relid=\\\"None\\\" ana_rel_type=\\\"annaphora_c\\\" style=\\\"background-color: {color};\\\">{combined_chunk}{anaphora_id}</anaphora>\")\n",
    "\n",
    "                # Locate and tag the antecedent in the referenced sentence\n",
    "                if ref_sentence_id_key in sentence_words:\n",
    "                    ref_sentence_words = sentence_words[ref_sentence_id_key]\n",
    "\n",
    "                    # Iterate through the referenced elements to find the correct antecedent\n",
    "                    for ref_element in ref_elements.values():\n",
    "                        if ref_element['name'] == word_info['ref_name']:\n",
    "                            combined_chunk_ref = ref_element['combined_chunk']\n",
    "\n",
    "                            # Store the antecedent ID and corresponding word in the new map\n",
    "                            antecedent_id = f\"{tagged_word_id}\"  # Use the next available tagged_word_id as antecedent ID\n",
    "                            antecedent_id_map[antecedent_id] = combined_chunk_ref  # Map ID to antecedent word\n",
    "\n",
    "                            # Update the antecedent_map with the current anaphora ID wrapped in <sup> tags\n",
    "                            if combined_chunk_ref not in antecedent_map:\n",
    "                                antecedent_map[combined_chunk_ref] = []\n",
    "                            # Append the current anaphora ID as a superscript tag\n",
    "                            antecedent_map[combined_chunk_ref].append(anaphora_id)  # Store <sup> tags in the map\n",
    "\n",
    "                            # Search through the referenced sentence words\n",
    "                            for k, chunk_word_candidate in enumerate(ref_sentence_words):\n",
    "                                if '<anaphora' in chunk_word_candidate:\n",
    "                                    # Check if the word candidate matches the combined_chunk_ref\n",
    "                                    match = re.search(r'<anaphora[^>]*>([^<]+)<', chunk_word_candidate)\n",
    "                                    if match:\n",
    "                                        actual_word = match.group(1)\n",
    "                                        if actual_word.strip() == combined_chunk_ref.strip():\n",
    "                                            existing_anaphora_tag = chunk_word_candidate\n",
    "                                            word_tag_id = f\"{tagged_word_id}\"\n",
    "                                            id_antecedent = word_tag_id\n",
    "                                            tagged_word_id += 1\n",
    "\n",
    "                                            # Create <sup> tags only if there are multiple anaphoras\n",
    "                                            existing_anaphora_ids = ''.join(antecedent_map[combined_chunk_ref]) if len(antecedent_map[combined_chunk_ref]) > 1 else \"\"\n",
    "                                            \n",
    "                                            # Update the antecedent HTML with current anaphora\n",
    "                                            ref_sentence_words[k] = f\"<antecedent class=\\\"antecedent-border highlightAnnaphora\\\" id=\\\"{id_antecedent}\\\" style=\\\"background-color: {color}; font-weight: bold;\\\">{existing_anaphora_tag}{existing_anaphora_ids}</antecedent>\"\n",
    "                                            \n",
    "                                            # Store the color and word in the map for antecedents\n",
    "                                            color_word_map[antecedent_id] = {'word': combined_chunk_ref, 'color': color}\n",
    "                                elif chunk_word_candidate.strip() == combined_chunk_ref.strip():\n",
    "                                    existing_tag = ref_sentence_words[k]\n",
    "                                    existing_anaphora_ids = ''.join(antecedent_map[combined_chunk_ref]) if len(antecedent_map[combined_chunk_ref]) > 1 else \"\"\n",
    "                                    word_tag_id = f\"{tagged_word_id}\"\n",
    "                                    id_antecedent = word_tag_id\n",
    "                                    tagged_word_id += 1\n",
    "\n",
    "                                    # Update the antecedent HTML accordingly\n",
    "                                    ref_sentence_words[k] = f\"<antecedent class=\\\"antecedent-border highlightAnnaphora\\\" id=\\\"{id_antecedent}\\\" style=\\\"background-color: {color}; font-weight: bold;\\\">{combined_chunk_ref}{existing_anaphora_ids}</antecedent>\"\n",
    "                                    \n",
    "                                    # Store the color and word in the map for antecedents\n",
    "                                    color_word_map[antecedent_id] = {'word': combined_chunk_ref, 'color': color}\n",
    "                            break  # Exit the loop once the ref_word is found\n",
    "\n",
    "                 # Append the anaphora HTML with its ID and style\n",
    "                words.append(f\"<anaphora id=\\\"{id_anaphora}\\\" class=\\\"highlightAnnaphora\\\" ana_ref=\\\"TRUE\\\" ana_relid=\\\"{id_antecedent}\\\" ana_rel_type=\\\"annaphora_c\\\" style=\\\"background-color: {color};\\\">{combined_chunk}{anaphora_id}</anaphora>\")\n",
    "            \n",
    "            else:\n",
    "                # If there is no reference, just append the word\n",
    "                words.append(word)\n",
    "\n",
    "        # Store the processed words for the current sentence in the sentence_words dictionary\n",
    "        sentence_id = f\"Sentence {i + 1}\"\n",
    "        sentence_words[sentence_id] = words\n",
    "\n",
    "    # After processing all sentences, update the antecedents in sentence_words\n",
    "    for antecedent_word, superscripts in antecedent_map.items():\n",
    "        for sentence_id, sentence in sentence_words.items():\n",
    "            for idx, word in enumerate(sentence):\n",
    "                if f\"{antecedent_word}\" in word:\n",
    "                     # Only append superscripts if the current word is an antecedent\n",
    "                    if f\"<antecedent\" in word:\n",
    "                        # Append the corresponding <sup> tags to the antecedent word before the closing tag\n",
    "                        sentence[idx] = re.sub(r\"(</antecedent>)\", f\"{''.join(superscripts)}\\\\1\", word)\n",
    "\n",
    "\n",
    "\n",
    "def extract_tags_and_colors(color_word_map):\n",
    "    tags_info = []\n",
    "\n",
    "    for tag_id, color_info in color_word_map.items():\n",
    "        word = color_info.get('word', '')\n",
    "        color = color_info.get('color', 'N/A')\n",
    "        tags_info.append((word, color))\n",
    "\n",
    "    # Convert the list of tuples into a dictionary with lists of colors\n",
    "    final_tags_info = {}\n",
    "    for word, color in tags_info:\n",
    "        color = rgb_to_hex(color)\n",
    "        if word in final_tags_info:\n",
    "            if color not in final_tags_info[word]:  # Avoid duplicate colors\n",
    "                final_tags_info[word].append(color)\n",
    "        else:\n",
    "            final_tags_info[word] = [color]\n",
    "\n",
    "    # Convert lists to a single string for output, allowing duplicates\n",
    "    final_tags_info = {key: ', '.join(colors) for key, colors in final_tags_info.items()}\n",
    "\n",
    "    #print(type(final_tags_info))\n",
    "    return final_tags_info\n",
    "\n",
    "\n",
    "\n",
    "def main(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        sentences = file.read().split('\\n\\n')\n",
    "\n",
    "    all_elements = [extract_elements(sentence) for sentence in sentences]\n",
    "    tag_coreferences(all_elements)\n",
    "    last_id = tagged_word_id  # Ensure you have the correct last ID\n",
    "\n",
    "    # Create the output dictionary\n",
    "    output_dict = {\n",
    "        \"text\": \"<document>\\n<metadata last_id=\\\"{}\\\"></metadata>\\n\".format(last_id),\n",
    "        \"last_id\": last_id,\n",
    "        \"colorMap\": {},\n",
    "        \"anaphora_count\": anaphora_counter\n",
    "    }\n",
    "\n",
    "    # Build the content for the document\n",
    "    for sentence_id, words in sentence_words.items():\n",
    "        output_dict[\"text\"] += f\"<paragraph>\\n<p>{' '.join(words)}</p>\\n</paragraph>\\n\\n<paragraph>\\n<p> </p>\\n</paragraph>\\n\\n\"\n",
    "    output_dict[\"text\"] += '</document>\\n'\n",
    "\n",
    "    # Fill the color_map with extracted information\n",
    "    tags_and_colors = extract_tags_and_colors(color_word_map)\n",
    "\n",
    "    # Ensure to include unique keys for colorMap\n",
    "    for tag, color in tags_and_colors.items():\n",
    "        output_dict[\"colorMap\"][tag] = color if color else \"N/A\"\n",
    "\n",
    "    # Properly escape the HTML-like content in the 'text' field for valid JSON\n",
    "    output_dict[\"text\"] = output_dict[\"text\"]\n",
    "\n",
    "    # Convert to JSON\n",
    "    json_output = json.dumps(output_dict, separators=(',', ':'))\n",
    "\n",
    "    # Print the final JSON output\n",
    "    #print(json_output)\n",
    "\n",
    "    # Set the timezone to IST\n",
    "    ist_timezone = timezone('Asia/Kolkata')\n",
    "    # Get the current date and time\n",
    "    now = datetime.datetime.now(ist_timezone)\n",
    "    # Format the date and time (customize as needed)\n",
    "    formatted_datetime = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # Write the JSON output to a file in the specified location\n",
    "    output_file_name = f'SSF_Conv_output_{formatted_datetime}.txt'\n",
    "    output_file_full_path = f'{output_file_path}/{output_file_name}'\n",
    "    with open(output_file_full_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_output)\n",
    "        print(f'Output written to: {output_file_full_path}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = input(\"Enter the absolute path of the input file: \")\n",
    "    output_directory = input(\"Enter the absolute path of the output directory: \")\n",
    "\n",
    "    # If the output directory is not provided, use the default \"Downloads\" directory\n",
    "    if not output_directory:\n",
    "        home_directory = os.path.expanduser(\"~\")  # Get the home directory of the user\n",
    "        output_directory = os.path.join(home_directory, \"Downloads\")\n",
    "\n",
    "    print(f\"Output will be saved to: {output_directory}\")\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Your code to process the input file and save results in the output directory\n",
    "    # For example, saving a file to the output directory\n",
    "    output_file_path = os.path.join(output_directory, \"output.txt\")\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        output_file.write(\"This is a test output.\")\n",
    "\n",
    "    print(f\"File saved to: {output_file_path}\")\n",
    "\n",
    "    main(input_file, output_directory)\n",
    "#/home/alexander/Downloads/nenu_annotated.txt\n",
    "#/home/alexander/Desktop/LTRC_IIIT_HYD/XML_frmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff629c-73be-48e7-a432-072829d9f957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
